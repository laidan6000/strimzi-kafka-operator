// Module included in the following assemblies:
//
// assembly-kafka-connect.adoc

[id='proc-deploying-kafkaconnector-{context}']
= Deploying the example `KafkaConnector` resource

Strimzi includes an example `KafkaConnector` in `examples/connect/source-connector.yaml`. 
This creates a basic `FileStreamSourceConnector` instance that sends each line of the Kafka license file (an example file source) to a single Kafka topic. 

You can create a `FileStreamSinkConnector` by changing the configuration of the example `KafkaConnector`.

The following procedure illustrates how to configure Kafka Connect connectors by using the `source-connector.yaml` file as an example. 

[NOTE]
====
The `FileStreamSourceConnector` and `FileStreamSinkConnector` are not intended to be run in containers. 
In a production environment, you should prepare container images containing the Kafka Connect connectors that you want to use.
====

.Prerequisites

* A Kafka Connect deployment
* link:{BookURLUsing}#proc-enabling-kafkaconnectors-deployment-configuration-kafka-connect[`KafkaConnectors` are enabled^]
* The Cluster Operator is running

.Procedure

. Edit the `examples/connect/source-connector.yaml` file:
+
[source,yaml,subs="attributes+"]
----
apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnector
metadata:
  name: my-source-connector <1>
  labels:
    strimzi.io/cluster: my-connect-cluster <2>
spec:
  class: org.apache.kafka.connect.file.FileStreamSourceConnector <3>
  tasksMax: 2 <4>
  config: <5>
    file: "/opt/kafka/LICENSE"
    topic: my-topic
    # ...
----
+
<1> Name of the `KafkaConnector` resource, which is used as the name of the connector. Use any name that is valid for a Kubernetes resource.
<2> Name of the Kafka Connect cluster to create the connector in.
<3> Full name or alias of the connector class. This should be present in the image being used by the Kafka Connect cluster.
<4> Maximum number of Kafka Connect `Tasks` that the connector can create.
<5> Connector configuration as key-value pairs.
+
The `FileStreamSourceConnector` class accepts the following configuration options:
+
[cols="4*",options="header",stripes="none",separator=¦]
|===

¦Name
¦Type
¦Default value
¦Description

m¦file
¦String
¦Null
¦Source file name. If not specified, the standard input is used.

m¦topic
¦List
¦Null
¦The Kafka topic to publish data to.

|===
+
The `FileStreamSinkConnector` class accepts the following configuration options
+
[cols="4*",options="header",stripes="none",separator=¦]
|===

¦Name
¦Type
¦Default value
¦Description

m¦file
¦String
¦Null
¦Destination file name. If not specified, the standard output is used.

m¦topics
¦List
¦Null
¦One or more Kafka topics to read data from.

m¦topics.regex
¦String
¦Null
¦A regular expression matching one or more Kafka topics to read data from.

|===
+
The `FileStreamSourceConnector` and `FileStreamSinkConnector` classes support the same configuration options as the Kafka Connect REST API. 
Other connectors will support different configuration options.

. Create the `KafkaConnector` in your Kubernetes cluster:
+
[source,shell,subs="+quotes"]
----
kubectl apply -f examples/connect/source-connector.yaml
----

. Check that the resource was created:
+
[source,shell,subs="+quotes"]
----
kubectl get kctr --selector strimzi.io/cluster=my-connect-cluster -o name
----

.Additional resources

* xref:con-creating-managing-connectors-{context}[]
